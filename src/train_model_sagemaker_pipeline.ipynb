{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "894dafb5-5186-4839-8258-c101f514e48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n",
      "✅ Using region: eu-west-3\n"
     ]
    }
   ],
   "source": [
    "# =====================================================================\n",
    "# STEP 1 — Imports and Configuration\n",
    "# =====================================================================\n",
    "\n",
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.xgboost import XGBoost\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "from sagemaker.workflow.steps import TrainingStep\n",
    "from sagemaker.model_metrics import ModelMetrics, MetricsSource\n",
    "from sagemaker.processing import ScriptProcessor, ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "from sagemaker.workflow.functions import Join\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.execution_variables import ExecutionVariables\n",
    "\n",
    "from sagemaker.workflow.parameters import ParameterInteger, ParameterString, ParameterFloat\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "bucket_param = ParameterString(name=\"Bucket\", default_value=\"ml-pipeline-project-aniolmg\")\n",
    "project_name_param = ParameterString(name=\"ProjectName\", default_value=\"titanic\")\n",
    "train_file_param = ParameterString(name=\"TrainFile\", default_value=\"titanic_train.csv\")\n",
    "test_file_param = ParameterString(name=\"TestFile\", default_value=\"titanic_test.csv\")\n",
    "\n",
    "train_s3 = Join(on=\"/\", values=[\"s3:/\", bucket_param, \"data\", train_file_param])\n",
    "\n",
    "pipeline_session = PipelineSession(default_bucket=\"ml-pipeline-project-aniolmg\")\n",
    "\n",
    "sm_client = boto3.client(\"sagemaker\")\n",
    "role = sagemaker.get_execution_role()\n",
    "output_s3 = Join(on=\"/\", values=[\"s3:/\", bucket_param, project_name_param, \"output\"])\n",
    "\n",
    "print(f\"✅ Using region: {region}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "686cdfe8-383f-4c97-9d39-0fa26aa961ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Ignoring unnecessary Python version: py3.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: ml.m5.large.\n"
     ]
    }
   ],
   "source": [
    "# =====================================================================\n",
    "# STEP 2 — Define and Configure the XGBoost Estimator\n",
    "# =====================================================================\n",
    "\n",
    "# Hyperparameters\n",
    "max_depth_param = ParameterInteger(name=\"MaxDepth\", default_value=8)\n",
    "eta_param = ParameterFloat(name=\"Eta\", default_value=0.3)\n",
    "num_round_param = ParameterInteger(name=\"NumRound\", default_value=200)\n",
    "objective_param = ParameterString(name=\"Objective\", default_value=\"binary:logistic\")\n",
    "target_param = ParameterString(name=\"Target\")\n",
    "feature_columns_param = ParameterString(name=\"FeatureColumns\")\n",
    "categorical_columns_param = ParameterString(name=\"CategoricalColumns\")\n",
    "\n",
    "xgb_estimator = XGBoost(\n",
    "    entry_point=\"train_model.py\",\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    framework_version=\"1.7-1\",\n",
    "    py_version=\"py3\",\n",
    "    output_path=Join(on=\"/\", values=[\"s3:/\", bucket_param, project_name_param, \"output\"]),\n",
    "    base_job_name=\"xgboost-train\",\n",
    "    hyperparameters={\n",
    "        \"max_depth\": max_depth_param,\n",
    "        \"eta\": eta_param,\n",
    "        \"objective\": objective_param,\n",
    "        \"num_round\": num_round_param,\n",
    "        \"train_file\": train_file_param,\n",
    "        \"target_column\": target_param,\n",
    "        \"feature_columns\": feature_columns_param,\n",
    "        \"categorical_columns\": categorical_columns_param,\n",
    "    },\n",
    "    sagemaker_session=pipeline_session,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e65906d9-cc87-48fa-842d-54978cb8bb72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Ignoring unnecessary Python version: py3.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    }
   ],
   "source": [
    "# =====================================================================\n",
    "# STEP 3 — Create Training, Metrics, and Registration Steps\n",
    "# =====================================================================\n",
    "\n",
    "# --- Training step ---\n",
    "train_step = TrainingStep(\n",
    "    name=\"TrainTitanicModel\",\n",
    "    estimator=xgb_estimator,\n",
    "    inputs={\"train\": TrainingInput(train_s3, content_type=\"csv\")},\n",
    ")\n",
    "\n",
    "# --- Define a ScriptProcessor for computing metrics ---\n",
    "script_processor = ScriptProcessor(\n",
    "    image_uri=sagemaker.image_uris.retrieve(\n",
    "        framework=\"xgboost\",\n",
    "        region=region,\n",
    "        version=\"1.7-1\",\n",
    "        py_version=\"py3\",\n",
    "    ),\n",
    "    command=[\"python3\"],\n",
    "    instance_type=\"ml.t3.medium\",\n",
    "    instance_count=1,\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "# --- ProcessingStep to compute metrics ---\n",
    "\n",
    "metrics_output_path = Join(\n",
    "    on=\"/\",\n",
    "    values=[\n",
    "        \"s3:/\",\n",
    "        bucket_param,\n",
    "        project_name_param,\n",
    "        \"metrics\",\n",
    "        ExecutionVariables.PIPELINE_EXECUTION_ID,\n",
    "    ]\n",
    ")\n",
    "\n",
    "metrics_step = ProcessingStep(\n",
    "    name=\"ComputeTitanicMetrics\",\n",
    "    processor=script_processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=train_step.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "            destination=\"/opt/ml/processing/model\",\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=Join(\n",
    "                on=\"/\",\n",
    "                values=[\n",
    "                    \"s3:/\",\n",
    "                    bucket_param,\n",
    "                    \"data\",\n",
    "                    test_file_param,\n",
    "                ]\n",
    "            ),\n",
    "            destination=\"/opt/ml/processing/data\",\n",
    "        ),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name=\"metrics\",\n",
    "            source=\"/opt/ml/processing/metrics\",\n",
    "            destination=metrics_output_path,\n",
    "        )\n",
    "    ],\n",
    "    code=\"compute_metrics.py\",\n",
    "    job_arguments=[\n",
    "        \"--input-model\", \"/opt/ml/processing/model\",\n",
    "        \"--input-data\", Join(on=\"/\", values=[\"/opt/ml/processing/data\", test_file_param]),\n",
    "        \"--output-metrics\", \"/opt/ml/processing/metrics\",\n",
    "        \"--target_column\", target_param,\n",
    "        \"--feature_columns\", feature_columns_param,\n",
    "        \"--categorical_columns\", categorical_columns_param,\n",
    "    ],\n",
    "    depends_on=[train_step],\n",
    ")\n",
    "\n",
    "# --- Define model metrics using the ProcessingStep output ---\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=Join(\n",
    "            on=\"/\",\n",
    "            values=[\n",
    "                metrics_step.properties.ProcessingOutputConfig.Outputs[\"metrics\"].S3Output.S3Uri,\n",
    "                \"metrics.json\"\n",
    "            ],\n",
    "        ),\n",
    "        content_type=\"application/json\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# --- Register the model using the metrics from ProcessingStep ---\n",
    "model_package_group_name = \"TitanicModel\"\n",
    "\n",
    "register_step = RegisterModel(\n",
    "    name=\"RegisterTitanicModel\",\n",
    "    estimator=xgb_estimator,\n",
    "    model_data=train_step.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    content_types=[\"text/csv\"],\n",
    "    response_types=[\"text/csv\"],\n",
    "    inference_instances=[\"ml.t2.medium\"],\n",
    "    transform_instances=[\"ml.m5.large\"],\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    approval_status=\"PendingManualApproval\",\n",
    "    model_metrics=model_metrics,\n",
    "    depends_on=[metrics_step],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d01efb7-1356-4aa9-882d-673a450927fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Starting pipeline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "WARNING:sagemaker.workflow._utils:Popping out 'CertifyForMarketplace' from the pipeline definition since it will be overridden in pipeline execution time.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ModelPackageName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "WARNING:sagemaker.workflow._utils:Popping out 'CertifyForMarketplace' from the pipeline definition since it will be overridden in pipeline execution time.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ModelPackageName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Pipeline executed successfully!\n"
     ]
    }
   ],
   "source": [
    "# =====================================================================\n",
    "# STEP 4 — Define and Execute SageMaker Pipeline\n",
    "# =====================================================================\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    name=\"TitanicPipeline\",\n",
    "    steps=[train_step, metrics_step, register_step],\n",
    "    sagemaker_session=pipeline_session,\n",
    "    parameters=[\n",
    "        bucket_param,\n",
    "        project_name_param,\n",
    "        max_depth_param,\n",
    "        eta_param,\n",
    "        num_round_param,\n",
    "        objective_param,\n",
    "        train_file_param,\n",
    "        test_file_param,\n",
    "        target_param,\n",
    "        feature_columns_param,\n",
    "        categorical_columns_param,\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"⏳ Starting pipeline...\")\n",
    "\n",
    "pipeline.upsert(role_arn=role)\n",
    "execution = pipeline.start(\n",
    "    parameters={\n",
    "        \"MaxDepth\": 6,\n",
    "        \"TrainFile\": \"titanic_train_2.csv\",\n",
    "        \"Target\": \"Survived\",\n",
    "        \"FeatureColumns\": \"Age,Sex,Pclass\",\n",
    "        \"CategoricalColumns\": \"Sex\",\n",
    "    }\n",
    ")\n",
    "execution.wait()\n",
    "\n",
    "\n",
    "print(\"✅ Pipeline executed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
